{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ce85abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import folium\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "217c8405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(440127, 75)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>COORD_L</th>\n",
       "      <th>COORD_W</th>\n",
       "      <th>road_name</th>\n",
       "      <th>road_category</th>\n",
       "      <th>n_VEHICLES</th>\n",
       "      <th>n_PARTICIPANTS</th>\n",
       "      <th>ID</th>\n",
       "      <th>n_DEATHS</th>\n",
       "      <th>...</th>\n",
       "      <th>severity</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>is_WEEKEND</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>is_NIGHT</th>\n",
       "      <th>is_PEAK_HOUR</th>\n",
       "      <th>is_toll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31.01.2015</td>\n",
       "      <td>81.151944</td>\n",
       "      <td>53.740000</td>\n",
       "      <td>Романово - Завьялово - Баево - Камень-на-Оби</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>161242174</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30.01.2015</td>\n",
       "      <td>85.018056</td>\n",
       "      <td>51.684444</td>\n",
       "      <td>Куяган - Куяча - Тоурак</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>161105683</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>30.01.2015</td>\n",
       "      <td>81.250000</td>\n",
       "      <td>53.818056</td>\n",
       "      <td>Барнаул - Камень-на-Оби - граница Новосибирско...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>161763431</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>24.01.2015</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>Быканов Мост - Солоновка - Солонешное - границ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>160331994</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>23.01.2015</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>Быканов Мост - Солоновка - Солонешное - границ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>160213415</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   REGION        DATE    COORD_L    COORD_W  \\\n",
       "0       1  31.01.2015  81.151944  53.740000   \n",
       "1       1  30.01.2015  85.018056  51.684444   \n",
       "2       1  30.01.2015  81.250000  53.818056   \n",
       "3       1  24.01.2015  51.000000  84.000000   \n",
       "4       1  23.01.2015  84.000000  53.000000   \n",
       "\n",
       "                                           road_name  road_category  \\\n",
       "0       Романово - Завьялово - Баево - Камень-на-Оби            5.0   \n",
       "1                            Куяган - Куяча - Тоурак            6.0   \n",
       "2  Барнаул - Камень-на-Оби - граница Новосибирско...            5.0   \n",
       "3  Быканов Мост - Солоновка - Солонешное - границ...            7.0   \n",
       "4  Быканов Мост - Солоновка - Солонешное - границ...            7.0   \n",
       "\n",
       "   n_VEHICLES  n_PARTICIPANTS         ID  n_DEATHS  ...  severity  YEAR  \\\n",
       "0           1               3  161242174         0  ...         2  2015   \n",
       "1           2               3  161105683         0  ...         2  2015   \n",
       "2           2               3  161763431         0  ...         1  2015   \n",
       "3           1               2  160331994         0  ...         1  2015   \n",
       "4           1               2  160213415         1  ...         3  2015   \n",
       "\n",
       "   MONTH  WEEKDAY  SEASON  is_WEEKEND  HOUR  is_NIGHT  is_PEAK_HOUR  is_toll  \n",
       "0      1        5       1           1     9         0             1        0  \n",
       "1      1        4       1           0    14         0             0        0  \n",
       "2      1        4       1           0    17         0             1        0  \n",
       "3      1        5       1           1    19         0             0        0  \n",
       "4      1        4       1           0    21         0             0        0  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/Настя/YandexDisk-n4skolesnikova/HSE 4th year/Graduation Thesis/data/ACCIDENT_LEVEL_DATA.csv\")\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46e26e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "toll_roads_df = df[df['is_toll'] == 1]\n",
    "free_roads_df = df[df['is_toll'] == 0]\n",
    "\n",
    "dbscan_toll = DBSCAN(eps=0.2/6371.0, min_samples=5, metric=\"haversine\")\n",
    "toll_roads_df.loc[:, \"cluster\"] = dbscan_toll.fit_predict(np.radians(toll_roads_df[[\"COORD_W\", \"COORD_L\"]].values))\n",
    "\n",
    "dbscan_free = DBSCAN(eps=0.3/6371.0, min_samples=5, metric=\"haversine\")    # larger eps for free ones as more observations\n",
    "free_roads_df.loc[:, \"cluster\"] = dbscan_free.fit_predict(np.radians(free_roads_df[[\"COORD_W\", \"COORD_L\"]].values))\n",
    "\n",
    "df = pd.concat([toll_roads_df, free_roads_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b03f6d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voronezh_center = [51.6608, 39.2003]\n",
    "# m = folium.Map(location=voronezh_center, zoom_start=6)\n",
    "\n",
    "# # Цвета для кластеров: красный для платных дорог, зелёный для бесплатных, серый для шума\n",
    "# cluster_colors = {\n",
    "#     1: \"red\",  # для платных дорог\n",
    "#     0: \"green\",  # для бесплатных дорог\n",
    "#     -1: \"gray\"  # шумовые точки\n",
    "# }\n",
    "\n",
    "# # Добавляем маркеры на карту\n",
    "# for idx, row in df.iterrows():\n",
    "#     # Определяем цвет в зависимости от дороги (is_toll)\n",
    "#     if row[\"is_toll\"] == 1:  # Платные дороги\n",
    "#         color = \"red\"\n",
    "#     elif row[\"is_toll\"] == 0:  # Бесплатные дороги\n",
    "#         color = \"green\"\n",
    "#     else:  # Шумовые точки\n",
    "#         color = \"gray\"\n",
    "\n",
    "#     folium.CircleMarker(\n",
    "#         location=[row[\"COORD_W\"], row[\"COORD_L\"]],\n",
    "#         radius=4,\n",
    "#         color=color,\n",
    "#         fill=True,\n",
    "#         fill_color=color,\n",
    "#         fill_opacity=0.6\n",
    "#     ).add_to(m)\n",
    "\n",
    "# m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdd55e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative examples (clusters with label -1)\n",
    "negative_examples = df[df[\"cluster\"] == -1]\n",
    "\n",
    "# Positive examples (clusters with labels 0, 1, 2, ...)\n",
    "positive_examples = df[df[\"cluster\"] != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5b378a",
   "metadata": {},
   "source": [
    "## Hypotheses testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dd3cb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class imbalance in hotspot dataset: 0.08205811707518727\n"
     ]
    }
   ],
   "source": [
    "imsbalance = positive_examples['is_toll'].sum() / positive_examples.shape[0]\n",
    "print(f\"Class imbalance in hotspot dataset: {imsbalance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ff583ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.945342\n",
      "         Iterations 6\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:               severity   No. Observations:               197868\n",
      "Model:                        MNLogit   Df Residuals:                   197826\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Wed, 23 Apr 2025   Pseudo R-squ.:                 0.05396\n",
      "Time:                        17:47:38   Log-Likelihood:            -1.8705e+05\n",
      "converged:                       True   LL-Null:                   -1.9772e+05\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==========================================================================================\n",
      "            severity=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                     40.3186      1.586     25.417      0.000      37.210      43.428\n",
      "is_toll                    0.3285      0.012     28.031      0.000       0.305       0.351\n",
      "n_VEHICLES                 0.0498      0.013      3.717      0.000       0.024       0.076\n",
      "n_PARTICIPANTS             0.1910      0.005     39.656      0.000       0.182       0.200\n",
      "n_drunk                   -0.0275      0.004     -6.194      0.000      -0.036      -0.019\n",
      "guilty_exp_avg             0.0016      0.000      3.546      0.000       0.001       0.002\n",
      "cause_factors_cat          0.0046      0.002      2.390      0.017       0.001       0.008\n",
      "exp_avg                    0.0040      0.001      6.923      0.000       0.003       0.005\n",
      "guilty_share               0.3659      0.038      9.645      0.000       0.292       0.440\n",
      "lighting_cat               0.0303      0.004      7.774      0.000       0.023       0.038\n",
      "site_objects_cat          -0.0042      0.002     -2.307      0.021      -0.008      -0.001\n",
      "maneuver_violation        -0.2543      0.014    -18.483      0.000      -0.281      -0.227\n",
      "wrong_way                  0.2394      0.014     17.315      0.000       0.212       0.267\n",
      "interference_violation     0.2240      0.053      4.204      0.000       0.120       0.328\n",
      "impaired_driving           0.3340      0.018     18.373      0.000       0.298       0.370\n",
      "pedestrian_violation       0.3554      0.059      6.016      0.000       0.240       0.471\n",
      "n_front_drive             -0.1982      0.007    -30.454      0.000      -0.211      -0.185\n",
      "vehicle_age_avg           -0.0207      0.001    -26.184      0.000      -0.022      -0.019\n",
      "road_rank_cat              0.0533      0.008      6.627      0.000       0.038       0.069\n",
      "TYPE_cat                  -0.0344      0.004     -8.922      0.000      -0.042      -0.027\n",
      "adj_objects_cat            0.0096      0.002      4.826      0.000       0.006       0.013\n",
      "------------------------------------------------------------------------------------------\n",
      "            severity=3       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                     37.8312      1.938     19.519      0.000      34.032      41.630\n",
      "is_toll                    0.4498      0.016     27.484      0.000       0.418       0.482\n",
      "n_VEHICLES                 0.2581      0.017     15.294      0.000       0.225       0.291\n",
      "n_PARTICIPANTS             0.3760      0.006     62.099      0.000       0.364       0.388\n",
      "n_drunk                    0.0027      0.006      0.465      0.642      -0.009       0.014\n",
      "guilty_exp_avg             0.0037      0.001      6.291      0.000       0.003       0.005\n",
      "cause_factors_cat          0.0093      0.003      3.357      0.001       0.004       0.015\n",
      "exp_avg                    0.0040      0.001      5.174      0.000       0.002       0.006\n",
      "guilty_share               0.4946      0.046     10.649      0.000       0.404       0.586\n",
      "lighting_cat               0.0956      0.005     17.663      0.000       0.085       0.106\n",
      "site_objects_cat           0.0280      0.003     10.348      0.000       0.023       0.033\n",
      "maneuver_violation        -0.6749      0.020    -34.354      0.000      -0.713      -0.636\n",
      "wrong_way                  0.6237      0.018     34.329      0.000       0.588       0.659\n",
      "interference_violation     0.2905      0.067      4.350      0.000       0.160       0.421\n",
      "impaired_driving           0.8138      0.022     36.488      0.000       0.770       0.857\n",
      "pedestrian_violation       1.3256      0.063     21.163      0.000       1.203       1.448\n",
      "n_front_drive             -0.3684      0.009    -40.096      0.000      -0.386      -0.350\n",
      "vehicle_age_avg           -0.0206      0.001    -21.399      0.000      -0.023      -0.019\n",
      "road_rank_cat              0.1490      0.012     12.342      0.000       0.125       0.173\n",
      "TYPE_cat                  -0.1187      0.005    -22.801      0.000      -0.129      -0.109\n",
      "adj_objects_cat            0.0313      0.003     10.950      0.000       0.026       0.037\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "sample_weights = compute_sample_weight(class_weight='balanced', y=positive_examples['is_toll'])\n",
    "df_weighted = positive_examples.loc[positive_examples.index.repeat(sample_weights.round().astype(int))]\n",
    "\n",
    "X = df_weighted[[\n",
    "    'is_toll', 'n_VEHICLES', 'n_PARTICIPANTS',\n",
    "    'n_drunk', 'guilty_exp_avg', 'cause_factors_cat',\n",
    "    'exp_avg', 'guilty_share', 'lighting_cat', 'site_objects_cat', \n",
    "    'maneuver_violation', 'wrong_way', 'interference_violation',\n",
    "    'impaired_driving', 'pedestrian_violation', 'n_front_drive',\n",
    "    'vehicle_age_avg', 'road_rank_cat', 'TYPE_cat', 'adj_objects_cat'\n",
    "]]\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "y = df_weighted['severity']\n",
    "\n",
    "model = sm.MNLogit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6744e04",
   "metadata": {},
   "source": [
    "We have once again confirmed the hypothesis that the probability of a severe accident is higher on toll roads than on free roads.\n",
    "\n",
    "Moreover, by comparing the coefficients for the `is_toll` feature between the model for the entire dataset (see the file `severity_hypotheses.ipynb`) and the model for hotspot areas, we can note that the coefficient for `is_toll` is significantly higher in the hotspot areas: for moderate severity accidents (`severity = 2`) — 0.3235, and for severe accidents (`severity = 3`) — 0.4115. In contrast, for all observations, the coefficients are considerably lower: 0.2609 for moderate severity and 0.2564 for severe accidents. This indicates that the influence of the `is_toll` feature on accident severity is stronger in hotspot areas compared to roads in general.\n",
    "\n",
    "This leads us to the idea of developing a model that can predict accident hotspots based on coordinates and additional features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37c0e56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8461250085202099\n",
      "F1 (macro): 0.8207581285790071\n"
     ]
    }
   ],
   "source": [
    "features = [\"COORD_L\", \"COORD_W\", \"site_objects_cat\", \"road_rank_cat\", \"adj_objects_cat\", \n",
    "            \"traffic_changes_cat\", \"road_defects_cat\", \"cause_factors_cat\", \"road_category\", \"is_toll\"]\n",
    "\n",
    "X_model = df[features]\n",
    "\n",
    "# Target variable: hotspots (1 = hotspot, 0 = not hotspot)\n",
    "y_model = np.where(df[\"cluster\"] != -1, 1, 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_model, y_model, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 (macro):\", f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db795802",
   "metadata": {},
   "source": [
    "Gradient boosting was also tried, but it resulted in 5% less quality on both metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468041f2",
   "metadata": {},
   "source": [
    "Example of prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59c9cfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is not a hot spot (low-risk area).\n"
     ]
    }
   ],
   "source": [
    "new_data = pd.DataFrame({\n",
    "    \"COORD_L\": [55.7558],\n",
    "    \"COORD_W\": [37.6173],\n",
    "    \"site_objects_cat\": [2],\n",
    "    \"road_rank_cat\": [1],\n",
    "    \"adj_objects_cat\": [3],\n",
    "    \"traffic_changes_cat\": [0],\n",
    "    \"road_defects_cat\": [1],\n",
    "    \"cause_factors_cat\": [0],\n",
    "    \"road_category\": [1],\n",
    "    \"is_toll\": [0]\n",
    "})\n",
    "\n",
    "new_prediction = rf_model.predict(new_data)\n",
    "\n",
    "if new_prediction[0] == 1:\n",
    "    print(\"This is a hot spot (high-risk area).\")\n",
    "else:\n",
    "    print(\"This is not a hot spot (low-risk area).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a97cfcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_07a48af8b4ad064cbc2f7130e590a734 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_07a48af8b4ad064cbc2f7130e590a734&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_07a48af8b4ad064cbc2f7130e590a734 = L.map(\n",
       "                &quot;map_07a48af8b4ad064cbc2f7130e590a734&quot;,\n",
       "                {\n",
       "                    center: [55.7558, 37.6173],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    ...{\n",
       "  &quot;zoom&quot;: 10,\n",
       "  &quot;zoomControl&quot;: true,\n",
       "  &quot;preferCanvas&quot;: false,\n",
       "}\n",
       "\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_a6d80904f3d843e1a22fd9b951175dc1 = L.tileLayer(\n",
       "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {\n",
       "  &quot;minZoom&quot;: 0,\n",
       "  &quot;maxZoom&quot;: 19,\n",
       "  &quot;maxNativeZoom&quot;: 19,\n",
       "  &quot;noWrap&quot;: false,\n",
       "  &quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;,\n",
       "  &quot;subdomains&quot;: &quot;abc&quot;,\n",
       "  &quot;detectRetina&quot;: false,\n",
       "  &quot;tms&quot;: false,\n",
       "  &quot;opacity&quot;: 1,\n",
       "}\n",
       "\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_a6d80904f3d843e1a22fd9b951175dc1.addTo(map_07a48af8b4ad064cbc2f7130e590a734);\n",
       "        \n",
       "    \n",
       "            var circle_marker_ce478d81507ae235cbf004265bf248fa = L.circleMarker(\n",
       "                [55.7558, 37.6173],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;blue&quot;, &quot;fillOpacity&quot;: 0.6, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 6, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_07a48af8b4ad064cbc2f7130e590a734);\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x22e1eb76070>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = folium.Map(location=[55.7558, 37.6173], zoom_start=10)\n",
    "\n",
    "# If it is hot spot, the marker is red, if not, the marker is blue\n",
    "color = \"red\" if new_prediction[0] == 1 else \"blue\"\n",
    "\n",
    "folium.CircleMarker(\n",
    "    location=[new_data[\"COORD_L\"][0], new_data[\"COORD_W\"][0]],\n",
    "    radius=6,\n",
    "    color=color,\n",
    "    fill=True,\n",
    "    fill_color=color,\n",
    "    fill_opacity=0.6\n",
    ").add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e59a5b",
   "metadata": {},
   "source": [
    "Since the model is trained on both toll and non-toll roads, and includes the `'is_toll'` feature along with only those features related to the geographical location and road characteristics, it can be useful for predicting dangerous areas on new toll roads. Observations from non-toll roads, unlike toll roads, almost entirely cover the country's territory, which will allow the model to identify hotspots on a new toll road, even if it is geographically far from previously built toll highways.\n",
    "\n",
    "Let's check it! We will try to train the model on data excluding the toll road M-1 and see how well the model performs in identifying hotspots for this road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56343857",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[~df['dor'].str.contains('М-1', case=False, na=False)]\n",
    "X_train = df_train[features]\n",
    "y_train = np.where(df_train[\"cluster\"] != -1, 1, 0)  # 1 = hotspot, 0 = not hotspot\n",
    "\n",
    "df_m1 = df[df['dor'].str.contains('М-1', case=False, na=False)]\n",
    "X_test = df_m1[features]\n",
    "y_test = np.where(df_m1[\"cluster\"] != -1, 1, 0)  # 1 = hotspot, 0 = not hotspot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a673d504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for М-1: 0.68481455563331\n",
      "F1 (macro) for М-1: 0.6166441473508499\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_m1 = rf_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_m1)\n",
    "f1_macro = f1_score(y_test, y_pred_m1, average='macro')\n",
    "\n",
    "print(\"Accuracy for М-1:\", accuracy)\n",
    "print(\"F1 (macro) for М-1:\", f1_macro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad35fa34",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15920c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7696589643968827\n",
      "F1 (macro): 0.6985103405019857\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(n_estimators=100, max_depth=4, learning_rate=0.1, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 (macro):\", f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8367f3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best parameters: {'colsample_bytree': 1, 'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Test Accuracy: 0.8044782223433985\n",
      "Test F1 (macro): 0.7557633915554123\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1_macro',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Test F1 (macro):\", f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d02947c",
   "metadata": {},
   "source": [
    "### Dl model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e84a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[~df['road_name'].str.contains('М-1', case=False, na=False)]\n",
    "X_train = df_train[features]\n",
    "y_train = np.where(df_train[\"cluster\"] != -1, 1, 0)  # 1 = hotspot, 0 = not hotspot\n",
    "\n",
    "df_m1 = df[df['road_name'].str.contains('М-1', case=False, na=False)]\n",
    "X_test = df_m1[features]\n",
    "y_test = np.where(df_m1[\"cluster\"] != -1, 1, 0)  # 1 = hotspot, 0 = not hotspot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ed8c89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COORD_L                float64\n",
       "COORD_W                float64\n",
       "site_objects_cat         int64\n",
       "road_rank_cat            int64\n",
       "adj_objects_cat          int64\n",
       "traffic_changes_cat      int64\n",
       "road_defects_cat         int64\n",
       "cause_factors_cat        int64\n",
       "road_category          float64\n",
       "is_toll                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2731eb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5413/5413 [00:18<00:00, 285.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5769 | Val Loss: 0.5520 | Val F1: 0.6314\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5413/5413 [00:17<00:00, 310.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5531 | Val Loss: 0.5438 | Val F1: 0.6244\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5413/5413 [00:15<00:00, 348.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5490 | Val Loss: 0.5414 | Val F1: 0.6143\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5413/5413 [00:14<00:00, 377.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5475 | Val Loss: 0.5425 | Val F1: 0.5934\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5413/5413 [00:14<00:00, 366.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5456 | Val Loss: 0.5379 | Val F1: 0.6359\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5413/5413 [00:14<00:00, 369.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5449 | Val Loss: 0.5400 | Val F1: 0.6126\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5413/5413 [00:14<00:00, 382.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5439 | Val Loss: 0.5354 | Val F1: 0.6185\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5413/5413 [00:16<00:00, 333.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5432 | Val Loss: 0.5345 | Val F1: 0.6353\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5413/5413 [00:16<00:00, 331.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5428 | Val Loss: 0.5344 | Val F1: 0.6277\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5413/5413 [00:19<00:00, 278.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5423 | Val Loss: 0.5392 | Val F1: 0.6089\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5413/5413 [00:12<00:00, 448.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5423 | Val Loss: 0.5351 | Val F1: 0.6340\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5413/5413 [00:11<00:00, 452.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5418 | Val Loss: 0.5378 | Val F1: 0.6272\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5413/5413 [00:12<00:00, 444.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5414 | Val Loss: 0.5418 | Val F1: 0.6081\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5413/5413 [00:14<00:00, 366.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5410 | Val Loss: 0.5341 | Val F1: 0.6008\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5413/5413 [00:16<00:00, 338.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5410 | Val Loss: 0.5337 | Val F1: 0.6183\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5413/5413 [00:15<00:00, 346.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5408 | Val Loss: 0.5337 | Val F1: 0.6465\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5413/5413 [00:14<00:00, 363.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5402 | Val Loss: 0.5313 | Val F1: 0.6422\n",
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5413/5413 [00:13<00:00, 405.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5403 | Val Loss: 0.5313 | Val F1: 0.6120\n",
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5413/5413 [00:13<00:00, 406.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5397 | Val Loss: 0.5316 | Val F1: 0.6313\n",
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5413/5413 [00:12<00:00, 419.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5398 | Val Loss: 0.5350 | Val F1: 0.6265\n",
      "Accuracy for М-1 (PyTorch NN): 0.6516445066480056\n",
      "F1 (macro) for М-1 (PyTorch NN): 0.6432188826331711\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.int64)\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train_tensor, y_train_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = TensorDataset(X_tr, y_tr)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = MLP(X_train_tensor.shape[1])\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 20\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    for X_batch, y_batch in tqdm(train_loader, desc=f\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            val_outputs = model(X_val_batch)\n",
    "            val_loss += criterion(val_outputs, y_val_batch).item()\n",
    "            preds = (val_outputs > 0.5).int()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(y_val_batch.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val F1: {val_f1:.4f}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_probs = model(X_test_tensor).numpy().flatten()\n",
    "    y_pred_m1 = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_m1)\n",
    "f1_macro = f1_score(y_test, y_pred_m1, average='macro')\n",
    "\n",
    "print(\"Accuracy for М-1 (PyTorch NN):\", accuracy)\n",
    "print(\"F1 (macro) for М-1 (PyTorch NN):\", f1_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80380849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
